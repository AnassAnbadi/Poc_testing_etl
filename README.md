# üöÄ ETL Testing PoC - Age Calculation Pipeline

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![PostgreSQL](https://img.shields.io/badge/postgresql-12%2B-blue.svg)](https://postgresql.org)
[![pytest](https://img.shields.io/badge/testing-pytest-green.svg)](https://pytest.org)
[![Great Expectations](https://img.shields.io/badge/validation-great--expectations-orange.svg)](https://greatexpectations.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Proof of Concept (PoC)** d√©montrant les meilleures pratiques de test et validation dans un pipeline ETL moderne avec **pytest** et **Great Expectations**.

## üìã Table des mati√®res

- [üéØ Objectif du projet](#-objectif-du-projet)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [‚ö° Quick Start](#-quick-start)
- [üìä Mod√®le de donn√©es](#-mod√®le-de-donn√©es)
- [üîÑ Pipeline ETL](#-pipeline-etl)
- [üß™ Strat√©gie de test](#-strat√©gie-de-test)
- [üìà Validation des donn√©es](#-validation-des-donn√©es)
- [üöÄ Utilisation](#-utilisation)
- [üîß Configuration](#-configuration)
- [üìö Documentation technique](#-documentation-technique)
- [ü§ù Contribution](#-contribution)

## üéØ Objectif du projet

Ce PoC illustre comment impl√©menter un pipeline ETL robuste avec une strat√©gie de test compl√®te combinant :

- **Tests unitaires et d'int√©gration** avec pytest
- **Validation de qualit√© des donn√©es** avec Great Expectations
- **Calcul m√©tier** : mise √† jour automatique de l'√¢ge bas√© sur la date de naissance
- **Architecture modulaire** et maintenable

### üé™ Cas d'usage

**Probl√©matique** : Mettre √† jour les colonnes `datenaissance` et `age` dans une table target bas√© sur une `snapshot_date` et valider la qualit√© des donn√©es.

**Solution** : Pipeline ETL avec double validation (pytest + Great Expectations)

## üèóÔ∏è Architecture

\`\`\`
etl_project/
‚îú‚îÄ‚îÄ üìÅ etl/                        # üîß Code ETL m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ extract.py                 # üì• Extraction des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ transform.py               # üîÑ Transformation et calcul d'√¢ge
‚îÇ   ‚îú‚îÄ‚îÄ load.py                    # üì§ Chargement des donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                   # üõ†Ô∏è Utilitaires et connexion DB
‚îú‚îÄ‚îÄ üìÅ config/                     # ‚öôÔ∏è Configuration
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                # üîß Param√®tres DB et ETL
‚îú‚îÄ‚îÄ üìÅ great_expectations/         # üìä Validation Great Expectations
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/              # üìå Points de contr√¥le
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ target_results_checkpoint.yml
‚îÇ   ‚îú‚îÄ‚îÄ expectations/             # üìã Suites d'attentes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ target_results_suite.json
‚îÇ   ‚îú‚îÄ‚îÄ validations/              # ‚úÖ R√©sultats des validations
‚îÇ   ‚îî‚îÄ‚îÄ great_expectations.yml    # üîß Configuration principale
‚îú‚îÄ‚îÄ üìÅ ge_runner/                  # üèÉ Runner Great Expectations
‚îÇ   ‚îî‚îÄ‚îÄ run_validation.py         # ‚ñ∂Ô∏è Ex√©cution des validations
‚îú‚îÄ‚îÄ üìÅ tests/                      # üß™ Tests pytest
‚îÇ   ‚îú‚îÄ‚îÄ test_etl.py               # üî¨ Tests unitaires ETL
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py               # ‚öôÔ∏è Configuration pytest
‚îú‚îÄ‚îÄ üìÅ scripts/                    # üìú Scripts SQL
‚îÇ   ‚îî‚îÄ‚îÄ create_tables.sql         # üóÉÔ∏è Cr√©ation des tables
‚îú‚îÄ‚îÄ üìÅ logs/                       # üìù Fichiers de logs
‚îú‚îÄ‚îÄ main.py                       # üéØ Orchestration pipeline
‚îú‚îÄ‚îÄ .env                          # üîê Variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt              # üì¶ D√©pendances Python
‚îî‚îÄ‚îÄ README.md                     # üìñ Documentation
\`\`\`

### üîß Stack technique

| Composant | Technologie | Version | R√¥le |
|-----------|-------------|---------|------|
| **Base de donn√©es** | PostgreSQL | 12+ | Stockage des donn√©es |
| **Langage** | Python | 3.8+ | D√©veloppement ETL |
| **ORM/DB** | SQLAlchemy + psycopg2 | 2.0+ | Connexion base de donn√©es |
| **Data Processing** | Pandas | 2.1+ | Manipulation des donn√©es |
| **Tests unitaires** | pytest | 7.4+ | Tests et couverture |
| **Validation donn√©es** | Great Expectations | 0.18+ | Qualit√© des donn√©es |
| **Configuration** | Pydantic + python-dotenv | 2.5+ | Gestion config |
| **Logging** | Loguru | 0.7+ | Logs structur√©s |

## ‚ö° Quick Start

### 1Ô∏è‚É£ Pr√©requis

\`\`\`bash
# V√©rifier les versions
python --version  # >= 3.8
psql --version    # >= 12
\`\`\`

### 2Ô∏è‚É£ Installation

\`\`\`bash
# Cloner le repository
git clone https://github.com/AnassAnbadi/Poc_testing_etl.git
cd Poc_testing_etl

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\\Scripts\\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
\`\`\`

### 3Ô∏è‚É£ Configuration base de donn√©es

\`\`\`bash
# Cr√©er la base de donn√©es
createdb etl_db

# Configurer les variables d'environnement
cp .env.example .env
# √âditer .env avec vos param√®tres
\`\`\`

### 4Ô∏è‚É£ Lancement rapide

\`\`\`bash
# Setup complet + ex√©cution
python main.py

# Ou √©tape par √©tape
python main.py --setup-only      # Setup uniquement
python main.py --snapshot-date 2024-01-01  # Date sp√©cifique
\`\`\`

## üìä Mod√®le de donn√©es

### üóÉÔ∏è Table source (\`source_table\`)

| Colonne | Type | Contrainte | Description |
|---------|------|------------|-------------|
| \`id\` | INTEGER | PRIMARY KEY | Identifiant unique |
| \`datenaissance\` | DATE | NOT NULL | Date de naissance |
| \`created_at\` | TIMESTAMP | DEFAULT NOW() | Date de cr√©ation |

### üéØ Table target (\`target_table\`)

| Colonne | Type | Contrainte | Description |
|---------|------|------------|-------------|
| \`snapshot_date\` | DATE | PRIMARY KEY | Date de snapshot |
| \`id\` | INTEGER | PRIMARY KEY | R√©f√©rence vers source |
| \`datenaissance\` | DATE | - | **√Ä remplir par ETL** |
| \`age\` | INTEGER | - | **√Ä calculer par ETL** |
| \`updated_at\` | TIMESTAMP | DEFAULT NOW() | Date de mise √† jour |

### üîÑ Logique m√©tier

\`\`\`python
# Calcul d'√¢ge
age = snapshot_date.year - birth_date.year
if (snapshot_date.month, snapshot_date.day) < (birth_date.month, birth_date.day):
    age -= 1
\`\`\`

## üîÑ Pipeline ETL

### üì• Extract (Extraction)

\`\`\`python
# Extraction des donn√©es source
source_df = extractor.extract_source_data()

# Extraction des donn√©es target pour une snapshot
target_df = extractor.extract_target_data(snapshot_date)
\`\`\`

### üîÑ Transform (Transformation)

\`\`\`python
# Transformation avec calcul d'√¢ge
transformed_df = transformer.transform_data(
    source_df, target_df, snapshot_date
)
\`\`\`

**√âtapes de transformation :**
1. ‚úÖ Merge des donn√©es source/target sur l'ID
2. ‚úÖ Mise √† jour des dates de naissance manquantes
3. ‚úÖ Calcul automatique de l'√¢ge
4. ‚úÖ Validation des donn√©es transform√©es

### üì§ Load (Chargement)

\`\`\`python
# Chargement avec gestion des doublons
success = loader.load_to_target(transformed_df, snapshot_date)
\`\`\`

**Strat√©gie de chargement :**
- üóëÔ∏è Suppression des donn√©es existantes pour la snapshot
- üì¶ Insertion par batch pour les performances
- üîÑ Transaction atomique

## üß™ Strat√©gie de test

### üî¨ Tests pytest

#### Tests unitaires

\`\`\`bash
# Ex√©cuter tous les tests
pytest tests/ -v

# Avec couverture de code
pytest tests/ -v --cov=etl --cov-report=html

# Tests sp√©cifiques
pytest tests/test_etl.py::TestETLUtils::test_calculate_age_normal_case -v
\`\`\`

#### Couverture des tests

| Module | Fonctionnalit√© | Tests |
|--------|----------------|-------|
| **utils.py** | Calcul d'√¢ge | ‚úÖ Cas normaux, limites, erreurs |
| **extract.py** | Extraction donn√©es | ‚úÖ Mocking DB, gestion erreurs |
| **transform.py** | Transformation | ‚úÖ Logique m√©tier, validation |
| **load.py** | Chargement | ‚úÖ Insertion, gestion conflits |
| **Pipeline** | Int√©gration | ‚úÖ End-to-end, rollback |

#### Exemples de tests

\`\`\`python
def test_calculate_age_normal_case():
    """Test calcul d'√¢ge standard"""
    birth_date = date(1990, 5, 15)
    snapshot_date = date(2024, 1, 1)
    age = calculate_age(birth_date, snapshot_date)
    assert age == 33

def test_transform_data_success():
    """Test transformation compl√®te"""
    result_df = transformer.transform_data(source_df, target_df, '2024-01-01')
    assert result_df['age'].notna().all()
    assert result_df['datenaissance'].notna().all()
\`\`\`

## üìà Validation des donn√©es

### üéØ Great Expectations

#### Configuration

\`\`\`yaml
# great_expectations/great_expectations.yml
datasources:
  postgres_datasource:
    class_name: Datasource
    execution_engine:
      class_name: SqlAlchemyExecutionEngine
      connection_string: postgresql://user:pass@localhost:5432/etl_db
\`\`\`

#### Expectations impl√©ment√©es

| Cat√©gorie | Expectation | Description |
|-----------|-------------|-------------|
| **Structure** | \`expect_column_to_exist\` | Colonnes requises pr√©sentes |
| **Compl√©tude** | \`expect_column_values_to_not_be_null\` | Pas de valeurs nulles |
| **Type** | \`expect_column_values_to_be_of_type\` | Types de donn√©es corrects |
| **Domaine** | \`expect_column_values_to_be_between\` | √Çges r√©alistes (0-150) |
| **Format** | \`expect_column_values_to_match_strftime_format\` | Format dates |
| **Coh√©rence** | \`expect_column_pair_values_A_to_be_greater_than_B\` | snapshot_date > datenaissance |

#### Ex√©cution des validations

\`\`\`bash
# Validation compl√®te
python ge_runner/run_validation.py

# Validation d'une snapshot sp√©cifique
python -c "
from ge_runner.run_validation import GreatExpectationsRunner
runner = GreatExpectationsRunner()
runner.validate_target_table('2024-01-01')
"
\`\`\`

#### Rapport de validation

Apr√®s validation, consulter le rapport HTML :
\`\`\`
great_expectations/uncommitted/data_docs/local_site/index.html
\`\`\`

## üöÄ Utilisation

### üéØ Commandes principales

\`\`\`bash
# üîß Setup initial (tables + donn√©es d'exemple)
python main.py --setup-only

# üöÄ Pipeline complet (toutes les snapshots)
python main.py

# üìÖ Traitement d'une snapshot sp√©cifique
python main.py --snapshot-date 2024-01-01

# üîç Validation uniquement
python main.py --validate-only

# ‚ö° Sans validation Great Expectations
python main.py --skip-validation
\`\`\`

### üìä Monitoring

#### Logs

\`\`\`bash
# Logs en temps r√©el
tail -f logs/etl_pipeline_$(date +%Y-%m-%d).log

# Logs avec niveau DEBUG
export LOG_LEVEL=DEBUG
python main.py
\`\`\`

#### M√©triques

Le pipeline g√©n√®re automatiquement :
- üìà Nombre d'enregistrements trait√©s
- ‚è±Ô∏è Temps d'ex√©cution par √©tape
- ‚úÖ Taux de succ√®s des validations
- üö® Alertes en cas d'erreur

### üîÑ Int√©gration continue

\`\`\`bash
# Script de test complet
#!/bin/bash
set -e

echo "üß™ Ex√©cution des tests..."
pytest tests/ -v --cov=etl --cov-report=term-missing

echo "üîç Validation des donn√©es..."
python ge_runner/run_validation.py

echo "üöÄ Test du pipeline..."
python main.py --snapshot-date 2024-01-01

echo "‚úÖ Tous les tests pass√©s!"
\`\`\`

## üîß Configuration

### üìÅ Variables d'environnement (\`.env\`)

\`\`\`env
# üóÉÔ∏è Configuration base de donn√©es
DB_HOST=localhost
DB_PORT=5432
DB_NAME=etl_db
DB_USER=postgres
DB_PASSWORD=your_secure_password

# ‚öôÔ∏è Configuration ETL
BATCH_SIZE=1000
MAX_RETRIES=3
LOG_LEVEL=INFO

# üîç Configuration Great Expectations
GE_CONTEXT_ROOT_DIR=great_expectations
\`\`\`

### ‚öôÔ∏è Param√®tres avanc√©s

\`\`\`python
# config/settings.py
class ETLConfig(BaseSettings):
    batch_size: int = 1000          # Taille des lots
    max_retries: int = 3            # Tentatives en cas d'erreur
    log_level: str = "INFO"         # Niveau de logging
    timeout_seconds: int = 300      # Timeout des requ√™tes
\`\`\`

## üìö Documentation technique

### üèóÔ∏è Patterns utilis√©s

- **üè≠ Factory Pattern** : Cr√©ation des connexions DB
- **üîß Builder Pattern** : Construction des requ√™tes SQL
- **üìã Strategy Pattern** : Diff√©rentes strat√©gies de validation
- **üéØ Dependency Injection** : Configuration modulaire

### üîç Bonnes pratiques

#### ‚úÖ Code Quality

- **Type hints** partout
- **Docstrings** pour toutes les fonctions
- **Logging structur√©** avec contexte
- **Gestion d'erreurs** robuste
- **Tests** avec couverture > 90%

#### üöÄ Performance

- **Traitement par batch** pour les gros volumes
- **Connexions pool√©es** pour la DB
- **Requ√™tes optimis√©es** avec index
- **Monitoring** des performances

#### üîí S√©curit√©

- **Variables d'environnement** pour les secrets
- **Validation des entr√©es** utilisateur
- **Transactions atomiques**
- **Logs sans donn√©es sensibles**

### üêõ D√©pannage

#### Erreurs communes

\`\`\`bash
# ‚ùå Erreur de connexion DB
ERROR: could not connect to server
# ‚úÖ Solution
export DB_HOST=localhost
export DB_PASSWORD=correct_password

# ‚ùå Tests pytest √©chouent
ImportError: No module named 'etl'
# ‚úÖ Solution
export PYTHONPATH=\${PWD}:\${PYTHONPATH}

# ‚ùå Great Expectations erreur
DataContextError: Unable to load config
# ‚úÖ Solution
great_expectations init --force
\`\`\`

#### Mode debug

\`\`\`bash
# üîç Debug complet
export LOG_LEVEL=DEBUG
python -m pdb main.py

# üß™ Tests avec d√©tails
pytest tests/ -v -s --tb=long --pdb
\`\`\`

## ü§ù Contribution

### üöÄ Comment contribuer

1. **Fork** le projet
2. **Cr√©er** une branche feature (\`git checkout -b feature/amazing-feature\`)
3. **Commit** vos changements (\`git commit -m 'Add amazing feature'\`)
4. **Push** vers la branche (\`git push origin feature/amazing-feature\`)
5. **Ouvrir** une Pull Request

### üìã Checklist avant PR

- [ ] ‚úÖ Tests passent (\`pytest tests/ -v\`)
- [ ] ‚úÖ Couverture > 90% (\`pytest --cov=etl\`)
- [ ] ‚úÖ Great Expectations OK (\`python ge_runner/run_validation.py\`)
- [ ] ‚úÖ Code format√© (\`black etl/ tests/\`)
- [ ] ‚úÖ Linting OK (\`flake8 etl/ tests/\`)
- [ ] ‚úÖ Documentation mise √† jour

### üéØ Roadmap

- [ ] üê≥ **Docker** : Containerisation compl√®te
- [ ] üîÑ **CI/CD** : GitHub Actions
- [ ] üìä **Monitoring** : Grafana + Prometheus
- [ ] üöÄ **Airflow** : Orchestration avanc√©e
- [ ] üìà **Data Lineage** : Tra√ßabilit√© des donn√©es
- [ ] üîç **Data Profiling** : Analyse automatique

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üë• Auteurs

- **Anass Anbadi** - *D√©veloppeur principal* - [@AnassAnbadi](https://github.com/AnassAnbadi)

## üôè Remerciements

- **Great Expectations** pour la validation des donn√©es
- **pytest** pour le framework de test
- **SQLAlchemy** pour l'ORM
- **Pandas** pour la manipulation des donn√©es

---

<div align="center">

**‚≠ê Si ce projet vous aide, n'h√©sitez pas √† lui donner une √©toile ! ‚≠ê**

[üêõ Signaler un bug](https://github.com/AnassAnbadi/Poc_testing_etl/issues) ‚Ä¢ 
[üí° Demander une fonctionnalit√©](https://github.com/AnassAnbadi/Poc_testing_etl/issues) ‚Ä¢ 
[üìñ Documentation](https://github.com/AnassAnbadi/Poc_testing_etl/wiki)

</div>
\`\`\`
